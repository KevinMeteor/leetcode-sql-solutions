
# Capital Gain/Loss


## ğŸ” Problem Summary
(stock_name, operation_day) is the primary key (combination of columns with unique values) for this table.
The operation column is an ENUM (category) of type ('Sell', 'Buy').

Each row of this table indicates that the stock which has stock_name had an operation on the day operation_day with the price.
It is guaranteed that each 'Sell' operation for a stock has a corresponding 'Buy' operation in a previous day. It is also guaranteed that each 'Buy' operation for a stock has a corresponding 'Sell' operation in an upcoming day.
 

Write a solution to report the Capital gain/loss for each stock.

The Capital gain/loss of a stock is the total gain or loss after buying and selling the stock one or many times.

Return the result table in any order.

---

# âœ… è§£æ³• 1ï¼šSigned Aggregation(æœ€ç›´è§€ã€å¿«é€Ÿ)

### âœ” æ€è·¯
Using signed aggregation by mapping Buy operations to negative prices and Sell operations to positive prices.

| åŠŸèƒ½   | MySQL          | MSSQL                |
| ----   | -------------- | -------------------- |
| æ¢ä»¶è¡¨é” | `IF()`         | `CASE WHEN`          |
| æµ®é»ä¿ç•™ | `-1.0 * price` | `-1.0 * price`       |
| æ¢ä»¶åŠ ç¸½ | `SUM(IF(...))` | `SUM(CASE WHEN ...)` |


### âœ” ä¸»è¦æŠ€å·§
- Conditional aggregation: SUM(CASE WHEN ... THEN value ELSE 0 END) or IF()
- GROUP BY

### âœ” Time Complexity: O(N) 
where N is the number of rows in the Stocks table.

### âœ” Space Complexity: O(S)
where S is the number of the unique stock_name.

---

# âœ… è§£æ³• 2ï¼šUNION ALL

### âœ” æ€è·¯
åˆ†åˆ¥åˆ†å‡ºå…©ç¨®äº¤æ˜“ Sell & Buy çš„è¡¨ï¼Œä¸¦ Union èµ·ä¾†æˆç‚ºæ–°çš„è¡¨ï¼Œ
è½‰æˆåŒä¸€ç¨®ã€Œsigned priceã€ï¼Œå†åŠ ç¸½é‡‘é¡ã€‚

1. Buy  -> -price => AS new_price
2. Sell -> +price => AS new_price
3. SUM(new_price)

### âœ” ä¸»è¦æŠ€å·§
- UNION ALL

### âœ” Time Complexity: O(N) 
where N is the number of rows in the Stocks table.

### âœ” Space Complexity: O(N) 
where N is the number of rows in the new table after UNION ALL.

---



<!-- # ğŸ§  æ€æƒ³èª¤å€
- Thinking SQL executes row-by-row  
- Assuming window functions are O(1)  
- Believing subqueries are always slower  

---

# ğŸ§ª é¢è©¦è¿½å•
1. What if tables are huge (100M rows)?
2. How would you index this schema?
3. Can you rewrite using window functions?
4. How does the query planner optimize this case?

--- -->
